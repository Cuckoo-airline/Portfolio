{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer churn forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project task: predict which of the bank's clients are going to cancel the services. The model will be used to prevent customer churn. For the study, historical data on customer behaviour and termination of agreements with the bank is provided.\n",
    "\n",
    "Data source: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metric is too simple and not informative with an imbalance of classes. So I'll use the F1 metric as a key metric (because precision and recall do not depend on the ratio of classes).\n",
    "\n",
    "To evaluate the quality of the models regardless of the classification threshold, I'll use the AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key words\n",
    "- Python\n",
    "- Pandas\n",
    "- Machine learning\n",
    "- OHE\n",
    "- Imbalanced classes (upsampling, downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data preparation</a></span>\n",
    "    <ul class=\"toc-item\"><li><span><a href=\"#Data-familarization\" data-toc-modified-id=\"Data-familarization-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data familarization</a></span></li>\n",
    "        <li><span><a href=\"#Data-preprocessing\" data-toc-modified-id=\"Data-preprocessing-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data preprocessing</a></span>\n",
    "        <ul class=\"toc-item\"><li><span><a href=\"#Check-for-duplicates\" data-toc-modified-id=\"Check-for-duplicates-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Check for duplicates</a></span></li>\n",
    "            <li><span><a href=\"#Encoding-of-qualitative-features\" data-toc-modified-id=\"Encoding-of-qualitative-features-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Encoding of qualitative features</a></span></li>\n",
    "            <li><span><a href=\"#Missings-processing\" data-toc-modified-id=\"Missings-processing-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Missings processing</a></span></li></ul></li></ul></li>\n",
    "            <li><span><a href=\"#Problem-research\" data-toc-modified-id=\"Problem-research-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Problem research</a></span>\n",
    "    <ul class=\"toc-item\"><li><span><a href=\"#Class-balance-research\" data-toc-modified-id=\"Class-balance-research-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Class balance research</a></span></li>\n",
    "        <li><span><a href=\"#Training-of-models-without-considering-imbalance\" data-toc-modified-id=\"Training-of-models-without-considering-imbalance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Training of models without considering imbalance</a></span></li>\n",
    "        <li><span><a href=\"#Selection-of-hyperparameters\" data-toc-modified-id=\"Selection-of-hyperparameters-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Selection of hyperparameters</a></span></li></ul></li>\n",
    "        <li><span><a href=\"#Fighting-imbalance\" data-toc-modified-id=\"Fighting-imbalance-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Fighting imbalance</a></span>\n",
    "    <ul class=\"toc-item\"><li><span><a href=\"#Upsampling\" data-toc-modified-id=\"Upsampling-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Upsampling</a></span></li>\n",
    "        <li><span><a href=\"#Downsampling\" data-toc-modified-id=\"Downsampling-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Downsampling</a></span></li></ul></li><li><span><a href=\"#Model-testing\" data-toc-modified-id=\"Model-testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model testing</a></span></li>\n",
    "        <li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Conclusions</a></span></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data familarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.utils import shuffle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('C:\\\\Users\\\\Яна\\\\Documents\\\\Прогр\\\\dfs\\\\Churn.csv')\n",
    "except Exception:\n",
    "    print('Data loading error')\n",
    "\n",
    "df.info()\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we have to do:\n",
    "- Columns 'Row number' and 'Surname' can be deleted, we do not need them;\n",
    "- Rename the rest, bring to the \"snake\" style;\n",
    "- Column with id of clients is useless for forecasting. So it can be deleted after checking for obvious duplicates;\n",
    "- Provide data by country in integer form;\n",
    "- There are no gaps in the gender column, so it can be replaced by a column with the corresponding category indices;\n",
    "- Column with 'Tenure' cast to integer type;\n",
    "- Also, the 'Tenure' column is the only one that has gaps. We need to look at them and choose a filling method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(df['CustomerId'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking by unique numbers - there are no duplicates in the table. We don't need this column anymore, we can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score geography  gender  age  tenure    balance  num_of_products  \\\n",
       "0           619    France  Female   42     2.0       0.00                1   \n",
       "1           608     Spain  Female   41     1.0   83807.86                1   \n",
       "2           502    France  Female   42     8.0  159660.80                3   \n",
       "3           699    France  Female   39     1.0       0.00                2   \n",
       "4           850     Spain  Female   43     2.0  125510.82                1   \n",
       "\n",
       "   has_cr_card  is_active_member  estimated_salary  exited  \n",
       "0            1                 1         101348.88       1  \n",
       "1            0                 1         112542.58       0  \n",
       "2            1                 0         113931.57       1  \n",
       "3            0                 0          93826.63       0  \n",
       "4            1                 1          79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop(['RowNumber', 'Surname', 'CustomerId'], axis = 1)\n",
    "df = df.rename({'CreditScore': 'credit_score', 'Geography': 'geography', 'Gender': 'gender', 'Age': 'age', \n",
    "                'Tenure': 'tenure', 'Balance': 'balance', 'NumOfProducts': 'num_of_products', \n",
    "                'HasCrCard': 'has_cr_card', 'IsActiveMember': 'is_active_member', \n",
    "                'EstimatedSalary': 'estimated_salary', 'Exited': 'exited'}, axis = 1)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete extra columns.\n",
    "\n",
    "Rename the rest.\n",
    "\n",
    "To create a column with a gender index, I'll write a function for one row.\n",
    "\n",
    "But to replace the data type in the tenure column, the gaps must be filled first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding of qualitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  age  tenure    balance  num_of_products  has_cr_card  \\\n",
       "0           619   42     2.0       0.00                1            1   \n",
       "1           608   41     1.0   83807.86                1            0   \n",
       "2           502   42     8.0  159660.80                3            1   \n",
       "3           699   39     1.0       0.00                2            0   \n",
       "4           850   43     2.0  125510.82                1            1   \n",
       "\n",
       "   is_active_member  estimated_salary  exited  geography_Germany  \\\n",
       "0                 1         101348.88       1                  0   \n",
       "1                 1         112542.58       0                  0   \n",
       "2                 0         113931.57       1                  0   \n",
       "3                 0          93826.63       0                  0   \n",
       "4                 1          79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['geography'].unique())\n",
    "\n",
    "df = pd.get_dummies(df, drop_first = True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the list of countries - there are only three, it is easy to assign indices. And there are only two genders in the table, and no discussions. Using OHE for encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missings processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>591</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>550</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>585</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>655</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>742</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>543</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26019.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>652</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114675.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>730</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85982.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>413</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6534.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>538</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108055.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27231.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>684</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126384.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198129.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>432</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152603.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110265.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>635</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138296.94</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141075.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>800</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108007.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47125.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>578</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169462.09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112187.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>850</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122311.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19482.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>730</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176576.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>567</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>167984.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>670</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170557.91</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>198252.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>539</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116220.50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55803.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     credit_score  age  tenure    balance  num_of_products  has_cr_card  \\\n",
       "30            591   39     NaN       0.00                3            1   \n",
       "48            550   38     NaN  103391.38                1            0   \n",
       "51            585   36     NaN  146050.97                2            0   \n",
       "53            655   41     NaN  125561.97                1            0   \n",
       "60            742   35     NaN  136857.00                1            0   \n",
       "82            543   36     NaN       0.00                2            0   \n",
       "85            652   75     NaN       0.00                2            1   \n",
       "94            730   42     NaN       0.00                2            0   \n",
       "99            413   34     NaN       0.00                2            0   \n",
       "111           538   39     NaN  108055.10                2            1   \n",
       "123           684   48     NaN  126384.42                1            1   \n",
       "125           432   42     NaN  152603.45                1            1   \n",
       "146           635   29     NaN  138296.94                2            1   \n",
       "162           800   49     NaN  108007.36                1            0   \n",
       "173           578   30     NaN  169462.09                1            1   \n",
       "180           850   45     NaN  122311.21                1            1   \n",
       "217           730   33     NaN       0.00                2            0   \n",
       "222           567   42     NaN       0.00                2            1   \n",
       "225           670   37     NaN  170557.91                2            1   \n",
       "237           539   43     NaN  116220.50                3            1   \n",
       "\n",
       "     is_active_member  estimated_salary  exited  geography_Germany  \\\n",
       "30                  0         140469.38       1                  0   \n",
       "48                  1          90878.13       0                  1   \n",
       "51                  0          86424.57       0                  1   \n",
       "53                  0         164040.94       1                  1   \n",
       "60                  0          84509.57       0                  1   \n",
       "82                  0          26019.59       0                  0   \n",
       "85                  1         114675.75       0                  0   \n",
       "94                  1          85982.47       0                  0   \n",
       "99                  0           6534.18       0                  0   \n",
       "111                 0          27231.26       0                  1   \n",
       "123                 1         198129.36       0                  1   \n",
       "125                 0         110265.24       1                  0   \n",
       "146                 0         141075.51       0                  0   \n",
       "162                 0          47125.11       0                  0   \n",
       "173                 0         112187.11       0                  0   \n",
       "180                 1          19482.50       0                  0   \n",
       "217                 0         176576.62       0                  0   \n",
       "222                 1         167984.61       0                  0   \n",
       "225                 0         198252.88       0                  0   \n",
       "237                 0          55803.96       1                  1   \n",
       "\n",
       "     geography_Spain  gender_Male  \n",
       "30                 1            0  \n",
       "48                 0            1  \n",
       "51                 0            1  \n",
       "53                 0            1  \n",
       "60                 0            1  \n",
       "82                 0            0  \n",
       "85                 1            0  \n",
       "94                 1            1  \n",
       "99                 0            1  \n",
       "111                0            1  \n",
       "123                0            0  \n",
       "125                0            1  \n",
       "146                1            0  \n",
       "162                0            0  \n",
       "173                0            1  \n",
       "180                1            0  \n",
       "217                1            0  \n",
       "222                0            1  \n",
       "225                0            1  \n",
       "237                0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[df['tenure'].isna()].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I'll look at the passes, suddenly they have some kind of system.\n",
    "\n",
    "But there is no system, just random gaps in the data. The data is homogeneous, and there are not expected to be any significant outliers in the values, I'll simply fill in the gaps with the average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.997690023099769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['tenure'].mean())\n",
    "df['tenure'] = df['tenure'].fillna(5)\n",
    "df = df.astype({'tenure': int})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I look at the average value. The value in the column is indicated in whole years, and the average, of course, is not a whole number. But it can be safely rounded up to five.\n",
    "\n",
    "Next, I fill in the gaps with the resulting value.\n",
    "\n",
    "And now nothing prevents to bring the column to an integer format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class balance research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df['exited'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that classes are balanced when the number of objects in them is approximately equal, or differs slightly. Let's check.\n",
    "\n",
    "Two thousand departed customers out of ten thousand in the dataset. 20%. The classes are obviously not balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of models without considering imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "\n",
      "(2000, 11)\n",
      "(2000,)\n",
      "\n",
      "(2000, 11)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "df_learn, df_test = train_test_split(df, test_size=0.20, random_state=12345)\n",
    "df_train, df_valid = train_test_split(df_learn, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train = df_train.drop(['exited'], axis = 1)\n",
    "target_train = df_train['exited']\n",
    "\n",
    "features_valid = df_valid.drop(['exited'], axis = 1)\n",
    "target_valid = df_valid['exited']\n",
    "\n",
    "features_test = df_test.drop(['exited'], axis = 1)\n",
    "target_test = df_test['exited']\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print()\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print()\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten thousand is a fairly solid sample, so that we can afford to split it into three - training, validation and test. I split according to the standard proportion 60/20/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-0.134048</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>-0.369113</td>\n",
       "      <td>0.076163</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.331571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>-1.010798</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>-0.007415</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.727858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>0.639554</td>\n",
       "      <td>1.353490</td>\n",
       "      <td>-1.454209</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.477006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.990168</td>\n",
       "      <td>2.116987</td>\n",
       "      <td>-1.092511</td>\n",
       "      <td>0.651725</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.100232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>0.567351</td>\n",
       "      <td>0.685430</td>\n",
       "      <td>0.715982</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  num_of_products  \\\n",
       "492      -0.134048 -0.078068 -0.369113  0.076163         0.816929   \n",
       "6655     -1.010798  0.494555 -0.007415  0.136391        -0.896909   \n",
       "4287      0.639554  1.353490 -1.454209  0.358435        -0.896909   \n",
       "42       -0.990168  2.116987 -1.092511  0.651725        -0.896909   \n",
       "8178      0.567351  0.685430  0.715982  0.813110         0.816929   \n",
       "\n",
       "      has_cr_card  is_active_member  estimated_salary  geography_Germany  \\\n",
       "492             0                 1          0.331571                  0   \n",
       "6655            1                 1         -0.727858                  0   \n",
       "4287            1                 1         -0.477006                  1   \n",
       "42              1                 1         -0.100232                  0   \n",
       "8178            1                 1          0.801922                  0   \n",
       "\n",
       "      geography_Spain  gender_Male  \n",
       "492                 0            0  \n",
       "6655                0            1  \n",
       "4287                0            1  \n",
       "42                  0            0  \n",
       "8178                0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using StandardScaler to scale the features. Scaling only features, not targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.8545\n",
      "Best depth: 5\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "    \n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions)\n",
    "        \n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the decision tree. Here I will experiment only with depth. I will limit the maximum to five in order to prevent retraining of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.859\n",
      "Best depth: 5\n",
      "Best number of estimators: 70\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "best_n_est = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    for n_est in range (30, 101, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators = n_est)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions)\n",
    "        \n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_n_est = n_est\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best number of estimators:\", best_n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the selection of forest hyperparameters, I use a nested loop.\n",
    "\n",
    "The optimal parameters are: 30 trees, 5 levels each.\n",
    "\n",
    "Regression. As far as I understand, it does not have hyperparameters that would be worth brute force, so I'll try to train it with the class_weight argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll train three different models - DTC, RFC, LR. Now I have an optimal hyperparameters for them. \n",
    "\n",
    "But first, I ran them without hyperparameter fitting. In order not to duplicate the code, I saved the first set of metrics in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics of models not considering the imbalance before the selection of hyperparameters\n",
    "\n",
    "Accuracy\n",
    "- Decision Tree: 0.792\n",
    "- Random Forest: 0.854\n",
    "- Linear Regression: 0.8145\n",
    "\n",
    "\n",
    "F1\n",
    "- Decision Tree: 0.48387096774193544\n",
    "- Random Forest: 0.5197368421052632\n",
    "- Linear Regression: 0.30131826741996237\n",
    "\n",
    "\n",
    "\n",
    "AUC-ROC\n",
    "- Decision Tree: 0.6809951694353532\n",
    "- Random Forest: 0.8062918144262055\n",
    "- Linear Regression: 0.7703391568208876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the forest is the best on this stage. The regression is in second place in terms of accuracy, but fails F1 score. Decision tree lags behind in all respects.\n",
    "\n",
    "F1 near tree and forest is about 0.5 - it's about the level of guessing. But the regression predicts class 1 with an accuracy of only 30% - which means that a rather high accuracy is due to a good prediction of class 0. Considering that 80% of the sample is zeros, that is not the result we need.\n",
    "\n",
    "The AUC-ROC of the forest looks impressive, and the regression is not far behind. But I suspect that this was not without the influence of imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth = 5, random_state = 12345)\n",
    "model_tree.fit(features_train, target_train)\n",
    "predictions_tree = model_tree.predict(features_valid)\n",
    "tree_prob_one_valid = model_tree.predict_proba(features_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I'm training models with hyperparameters.\n",
    "\n",
    "I also calculate here the probability of class 1 for each model in order to further calculate the AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(max_depth = 5, n_estimators = 30, random_state = 12345)\n",
    "model_forest.fit(features_train, target_train)\n",
    "predictions_forest = model_forest.predict(features_valid)\n",
    "forest_prob_one_valid = model_forest.predict_proba(features_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear', random_state = 12345)\n",
    "model_lr.fit(features_train, target_train)\n",
    "predictions_lr = model_lr.predict(features_valid)\n",
    "lr_prob_one_valid = model_lr.predict_proba(features_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of models not considering the imbalance after the selection of hyperparameters\n",
      "Accuracy\n",
      "Decision Tree: 0.8545\n",
      "Random Forest: 0.857\n",
      "Linear Regression: 0.705\n",
      "\n",
      "F1\n",
      "Decision Tree: 0.5488372093023256\n",
      "Random Forest: 0.4723247232472325\n",
      "Linear Regression: 0.4741532976827095\n",
      "\n",
      "AUC-ROC\n",
      "Decision Tree: 0.8224509194603883\n",
      "Random Forest: 0.8359483658894422\n",
      "Linear Regression: 0.7725660805030526\n"
     ]
    }
   ],
   "source": [
    "print('Metrics of models not considering the imbalance after the selection of hyperparameters')\n",
    "print('Accuracy')\n",
    "print('Decision Tree:', accuracy_score(target_valid, predictions_tree))\n",
    "print('Random Forest:', accuracy_score(target_valid, predictions_forest))\n",
    "print('Linear Regression:', accuracy_score(target_valid, predictions_lr))\n",
    "print()\n",
    "print('F1')\n",
    "print('Decision Tree:', f1_score(target_valid, predictions_tree))\n",
    "print('Random Forest:', f1_score(target_valid, predictions_forest))\n",
    "print('Linear Regression:', f1_score(target_valid, predictions_lr))\n",
    "print()\n",
    "print('AUC-ROC')\n",
    "print('Decision Tree:', roc_auc_score(target_valid, tree_prob_one_valid))\n",
    "print('Random Forest:', roc_auc_score(target_valid, forest_prob_one_valid))\n",
    "print('Linear Regression:', roc_auc_score(target_valid, lr_prob_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After optimizing the hyperparameters, the metrics changed noticeably. The accuracy of the regression has slightly decreased, but F1 has grown, overtaking even a random forest. Perhaps now we cannot call the forest model the undisputed leader, it is not yet clear between the forest and the tree which is better. The regression is still lagging, but not as much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fighting imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will take two approaches - upsampling and downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_train_up, target_train_up = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7625\n",
      "Best depth: 5\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train_up, target_train_up)\n",
    "    tree_up_predict = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, tree_up_predict)\n",
    "        \n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7805\n",
      "Best depth: 5\n",
      "Best number of estimators: 30\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "best_n_est = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    for n_est in range (30, 101, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators = n_est)\n",
    "        model.fit(features_train_up, target_train_up)\n",
    "        forest_up_predict = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, forest_up_predict)\n",
    "        \n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_n_est = n_est\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best number of estimators:\", best_n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reselect hyperparameters considering the changed conditions.\n",
    "\n",
    "Nothing has changed, the hyperparameters remain the same. Then I create and train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_up = DecisionTreeClassifier(max_depth = 5, random_state = 12345)\n",
    "model_tree_up.fit(features_train_up, target_train_up)\n",
    "predictions_tree_up = model_tree_up.predict(features_valid)\n",
    "\n",
    "model_forest_up = RandomForestClassifier(max_depth = 5, n_estimators = 30, random_state = 12345)\n",
    "model_forest_up.fit(features_train_up, target_train_up)\n",
    "predictions_forest_up = model_forest_up.predict(features_valid)\n",
    "\n",
    "model_lr_up = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model_lr_up.fit(features_train_up, target_train_up)\n",
    "predictions_lr_up = model_lr_up.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after upsampling:\n",
      "DTC 0.7625\n",
      "RFC 0.7805\n",
      "LR 0.703\n",
      "\n",
      "F1 after upsampling:\n",
      "DTC: 0.5489078822412156\n",
      "RFC: 0.5587939698492462\n",
      "LR: 0.4771126760563381\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy after upsampling:')\n",
    "print('DTC', accuracy_score(target_valid, predictions_tree_up))\n",
    "print('RFC', accuracy_score(target_valid, predictions_forest_up))\n",
    "print('LR', accuracy_score(target_valid, predictions_lr_up))\n",
    "print()\n",
    "print('F1 after upsampling:')\n",
    "print('DTC:', f1_score(target_valid, predictions_tree_up))\n",
    "print('RFC:', f1_score(target_valid, predictions_forest_up))\n",
    "print('LR:', f1_score(target_valid, predictions_lr_up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I recheck the accuracy and F1.\n",
    "\n",
    "The regression metrics were almost unchanged. The DTC and RFC lost in accuracy, but RFC at the same time significantly increased F1. On a sample balanced by upsampling, the random forest seems to be the most successful model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_train_down, target_train_down = downsample(features_train, target_train, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to throw away the excess of zeros. In order for the classes to become equal, we need to remove 3/4 of zeros. The soul of the researcher hurts when 60% of the sample goes to the trash can, but the salary will hurt from getting bad predictions. So we cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.7835\n",
      "Best depth: 3\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train_down, target_train_down)\n",
    "    tree_down_predict = model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, tree_down_predict)\n",
    "        \n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.776\n",
      "Best depth: 4\n",
      "Best number of estimators: 100\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_depth = 0\n",
    "best_n_est = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    for n_est in range (30, 101, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators = n_est)\n",
    "        model.fit(features_train_down, target_train_down)\n",
    "        forest_down_predict = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, forest_down_predict)\n",
    "        \n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            best_depth = depth\n",
    "            best_n_est = n_est\n",
    "\n",
    "print(\"Best accuracy:\", best_result)\n",
    "print(\"Best depth:\", best_depth)\n",
    "print(\"Best number of estimators:\", best_n_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after downsampling, the optimal parameters have changed. Training models with new hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_down = DecisionTreeClassifier(max_depth = 3, random_state = 12345)\n",
    "model_tree_down.fit(features_train_down, target_train_down)\n",
    "predictions_tree_down = model_tree_down.predict(features_valid)\n",
    "\n",
    "model_forest_down = RandomForestClassifier(max_depth = 4, n_estimators = 100, random_state = 12345)\n",
    "model_forest_down.fit(features_train_down, target_train_down)\n",
    "predictions_forest_down = model_forest_down.predict(features_valid)\n",
    "\n",
    "model_lr_down = LogisticRegression(random_state = 12345, solver = 'liblinear')\n",
    "model_lr_down.fit(features_train_down, target_train_down)\n",
    "predictions_lr_down = model_lr_down.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after downsampling:\n",
      "DTC 0.7835\n",
      "RFC 0.776\n",
      "LR 0.7015\n",
      "\n",
      "F1 after downsampling:\n",
      "DTC: 0.5118376550169109\n",
      "RFC: 0.554671968190855\n",
      "LR: 0.47493403693931396\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy after downsampling:')\n",
    "print('DTC', accuracy_score(target_valid, predictions_tree_down))\n",
    "print('RFC', accuracy_score(target_valid, predictions_forest_down))\n",
    "print('LR', accuracy_score(target_valid, predictions_lr_down))\n",
    "print()\n",
    "print('F1 after downsampling:')\n",
    "print('DTC:', f1_score(target_valid, predictions_tree_down))\n",
    "print('RFC:', f1_score(target_valid, predictions_forest_down))\n",
    "print('LR:', f1_score(target_valid, predictions_lr_down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values have changed somewhat, but fluctuate at about the same level. The metrics of the tree and the forest have decreased by 1-3%, the regression kept its level. \n",
    "\n",
    "I'll start testing with a random forest model trained on an upsampled sample as having the best metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7955\n",
      "F1: 0.6123222748815166\n",
      "AUC-ROC: 0.8555795917941968\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model_forest_up.predict(features_test)\n",
    "test_1_prob = model_forest_up.predict_proba(features_test)[:, 1]\n",
    "\n",
    "print('Accuracy:', accuracy_score(target_test, test_predictions))\n",
    "print('F1:', f1_score(target_test, test_predictions))\n",
    "print('AUC-ROC:', roc_auc_score(target_test, test_1_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1573\n",
      "1     427\n",
      "Name: exited, dtype: int64\n",
      "\n",
      "0    1372\n",
      "1     628\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(target_test).value_counts())\n",
    "print()\n",
    "print(pd.Series(test_predictions).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of interest, I'll look at the proportions of the classes. There are more ones in the predictions than in the target sample, the model is clearly prone to false positive answers. This probably explains the low F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model:\n",
      "Accuracy: 0.7955\n",
      "AUC-ROC: 0.8555795917941968\n",
      "\n",
      "Constant model:\n",
      "Accuracy: 0.7865\n",
      "AUC-ROC: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "const_predict = pd.Series(0, index = target_test.index)\n",
    "\n",
    "print('Final model:')\n",
    "print('Accuracy:', accuracy_score(target_test, test_predictions))\n",
    "print('AUC-ROC:', roc_auc_score(target_test, test_1_prob))\n",
    "print()\n",
    "print('Constant model:')\n",
    "print('Accuracy:', accuracy_score(target_test, const_predict))\n",
    "print('AUC-ROC:', roc_auc_score(target_test, const_predict))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_test, model_forest_up.predict_proba(features_test)[:, 1]) \n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will check the model for adequacy. I create a constant model, and check accuracy and AUC-ROC for both models.\n",
    "\n",
    "Interesting. With a significant difference in AUC-ROC, the final model is only 1% more accurate than the random one. However, more precisely, so that the model can be considered adequate. The shape of the ROC curve confirms this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the predictions of this model, the bank will make about a third more customers happy with super-offers than it was going to leave. However, given the dynamics, they should focus not on targeted work with the leaving clients, but on improving conditions for clients in general."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1054,
    "start_time": "2022-02-17T16:37:29.806Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-17T16:41:02.150Z"
   },
   {
    "duration": 377,
    "start_time": "2022-02-17T17:16:12.908Z"
   },
   {
    "duration": 187,
    "start_time": "2022-02-17T17:16:34.879Z"
   },
   {
    "duration": 190,
    "start_time": "2022-02-17T17:17:40.490Z"
   },
   {
    "duration": 199,
    "start_time": "2022-02-17T17:18:08.734Z"
   },
   {
    "duration": 214,
    "start_time": "2022-02-17T17:18:45.929Z"
   },
   {
    "duration": 172,
    "start_time": "2022-02-17T17:18:48.718Z"
   },
   {
    "duration": 979,
    "start_time": "2022-02-17T17:18:57.096Z"
   },
   {
    "duration": 1081,
    "start_time": "2022-02-17T17:19:07.105Z"
   },
   {
    "duration": 46,
    "start_time": "2022-02-17T17:19:10.552Z"
   },
   {
    "duration": 276,
    "start_time": "2022-02-17T17:19:14.500Z"
   },
   {
    "duration": 236,
    "start_time": "2022-02-17T17:20:14.385Z"
   },
   {
    "duration": 179,
    "start_time": "2022-02-17T17:20:34.349Z"
   },
   {
    "duration": 1025,
    "start_time": "2022-02-17T17:21:36.334Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-17T17:21:37.361Z"
   },
   {
    "duration": 274,
    "start_time": "2022-02-17T17:21:42.320Z"
   },
   {
    "duration": 4958,
    "start_time": "2022-02-17T17:22:09.543Z"
   },
   {
    "duration": 189,
    "start_time": "2022-02-17T17:23:23.000Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-17T17:23:45.707Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-17T17:24:02.339Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-17T17:24:16.861Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-17T17:24:22.783Z"
   },
   {
    "duration": 1017,
    "start_time": "2022-02-17T17:24:35.460Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-17T17:24:36.479Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-17T17:24:43.762Z"
   },
   {
    "duration": 126,
    "start_time": "2022-02-17T17:25:14.958Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-18T17:04:51.566Z"
   },
   {
    "duration": 54,
    "start_time": "2022-02-18T17:04:51.580Z"
   },
   {
    "duration": 226,
    "start_time": "2022-02-18T17:04:51.637Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-18T17:05:03.403Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-18T17:06:03.769Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-18T17:06:47.048Z"
   },
   {
    "duration": 324,
    "start_time": "2022-02-18T17:09:16.900Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-18T17:16:51.097Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-18T17:17:19.390Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-18T17:18:26.271Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-18T17:19:28.356Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T17:21:51.316Z"
   },
   {
    "duration": 1358,
    "start_time": "2022-02-18T17:22:22.785Z"
   },
   {
    "duration": 70,
    "start_time": "2022-02-18T17:22:24.146Z"
   },
   {
    "duration": 250,
    "start_time": "2022-02-18T17:22:24.219Z"
   },
   {
    "duration": 40,
    "start_time": "2022-02-18T17:22:24.473Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-18T17:22:27.411Z"
   },
   {
    "duration": 385,
    "start_time": "2022-02-18T17:24:19.423Z"
   },
   {
    "duration": 427,
    "start_time": "2022-02-18T17:25:39.670Z"
   },
   {
    "duration": 1374,
    "start_time": "2022-02-18T17:26:21.067Z"
   },
   {
    "duration": 78,
    "start_time": "2022-02-18T17:26:22.444Z"
   },
   {
    "duration": 251,
    "start_time": "2022-02-18T17:26:22.525Z"
   },
   {
    "duration": 39,
    "start_time": "2022-02-18T17:26:22.779Z"
   },
   {
    "duration": 418,
    "start_time": "2022-02-18T17:26:28.387Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-18T17:27:28.310Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-18T17:35:41.386Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-18T17:36:05.750Z"
   },
   {
    "duration": 55,
    "start_time": "2022-02-18T17:38:08.857Z"
   },
   {
    "duration": 6179,
    "start_time": "2022-02-18T17:43:26.032Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-18T17:44:08.890Z"
   },
   {
    "duration": 1322,
    "start_time": "2022-02-18T17:44:44.512Z"
   },
   {
    "duration": 73,
    "start_time": "2022-02-18T17:44:45.837Z"
   },
   {
    "duration": 223,
    "start_time": "2022-02-18T17:44:45.913Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-18T17:44:46.139Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-18T17:44:46.170Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-18T17:44:51.689Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-18T17:44:57.562Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-18T17:47:20.945Z"
   },
   {
    "duration": 383,
    "start_time": "2022-02-18T18:11:12.573Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-18T18:12:04.673Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-18T18:17:03.019Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-18T18:18:22.493Z"
   },
   {
    "duration": 327,
    "start_time": "2022-02-19T11:29:02.469Z"
   },
   {
    "duration": 978,
    "start_time": "2022-02-19T11:29:06.990Z"
   },
   {
    "duration": 59,
    "start_time": "2022-02-19T11:29:07.969Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-19T11:29:08.030Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-19T11:29:08.037Z"
   },
   {
    "duration": 115,
    "start_time": "2022-02-19T11:29:08.052Z"
   },
   {
    "duration": 7833,
    "start_time": "2022-02-19T11:29:11.895Z"
   },
   {
    "duration": 986,
    "start_time": "2022-02-19T11:29:56.482Z"
   },
   {
    "duration": 48,
    "start_time": "2022-02-19T11:29:57.470Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-19T11:29:57.520Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-19T11:29:57.525Z"
   },
   {
    "duration": 129,
    "start_time": "2022-02-19T11:29:57.554Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-19T11:30:00.390Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-19T11:32:23.613Z"
   },
   {
    "duration": 1005,
    "start_time": "2022-02-19T11:39:45.489Z"
   },
   {
    "duration": 60,
    "start_time": "2022-02-19T11:39:46.496Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-19T11:39:46.558Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-19T11:39:46.565Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-19T11:39:46.580Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-19T11:40:11.900Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-19T11:46:03.270Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-19T12:01:43.255Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-19T12:04:53.711Z"
   },
   {
    "duration": 1217,
    "start_time": "2022-02-21T07:44:58.883Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-21T07:45:00.102Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-21T07:45:00.153Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-21T07:45:00.161Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-21T07:45:00.181Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-21T07:45:00.210Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-21T07:45:00.229Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-21T07:45:00.264Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-21T07:45:00.271Z"
   },
   {
    "duration": 378,
    "start_time": "2022-02-21T07:45:00.294Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-21T07:49:08.676Z"
   },
   {
    "duration": 86,
    "start_time": "2022-02-21T07:57:36.904Z"
   },
   {
    "duration": 372,
    "start_time": "2022-02-21T08:21:31.853Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-21T08:21:47.176Z"
   },
   {
    "duration": 75,
    "start_time": "2022-02-21T08:21:49.399Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-21T08:21:52.694Z"
   },
   {
    "duration": 1334,
    "start_time": "2022-02-21T09:10:10.406Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-21T09:11:01.836Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-21T09:11:14.986Z"
   },
   {
    "duration": 314,
    "start_time": "2022-02-21T09:12:49.355Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-21T09:12:54.910Z"
   },
   {
    "duration": 403,
    "start_time": "2022-02-21T09:12:57.454Z"
   },
   {
    "duration": 318,
    "start_time": "2022-02-21T09:13:27.780Z"
   },
   {
    "duration": 271,
    "start_time": "2022-02-21T09:14:05.501Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-21T09:14:18.874Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-21T09:16:06.861Z"
   },
   {
    "duration": 578,
    "start_time": "2022-02-21T09:18:17.175Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-21T09:18:28.709Z"
   },
   {
    "duration": 459,
    "start_time": "2022-02-21T09:18:31.896Z"
   },
   {
    "duration": 1845,
    "start_time": "2022-02-21T09:20:02.647Z"
   },
   {
    "duration": 56,
    "start_time": "2022-02-21T09:20:04.494Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-21T09:20:04.552Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-21T09:20:04.561Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-21T09:20:04.579Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-21T09:20:04.604Z"
   },
   {
    "duration": 43,
    "start_time": "2022-02-21T09:20:04.620Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-21T09:20:04.665Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-21T09:20:04.673Z"
   },
   {
    "duration": 3854,
    "start_time": "2022-02-21T09:20:12.378Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-21T09:21:34.770Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-21T09:21:47.236Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-21T09:24:32.539Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-21T09:25:18.023Z"
   },
   {
    "duration": 72,
    "start_time": "2022-02-21T09:25:21.471Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-21T09:25:26.695Z"
   },
   {
    "duration": 527,
    "start_time": "2022-02-21T09:26:10.133Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-21T09:26:38.007Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-21T09:29:01.592Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-21T09:30:08.925Z"
   },
   {
    "duration": 944,
    "start_time": "2022-02-21T09:37:27.158Z"
   },
   {
    "duration": 330,
    "start_time": "2022-02-21T09:38:13.402Z"
   },
   {
    "duration": 3,
    "start_time": "2022-02-21T09:38:55.270Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-21T09:39:02.135Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-21T10:00:49.659Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-21T10:07:18.701Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-21T10:09:24.386Z"
   },
   {
    "duration": 161,
    "start_time": "2022-02-21T10:11:30.001Z"
   },
   {
    "duration": 504,
    "start_time": "2022-02-21T10:14:09.879Z"
   },
   {
    "duration": 156,
    "start_time": "2022-02-21T10:18:34.468Z"
   },
   {
    "duration": 397,
    "start_time": "2022-02-21T10:19:24.344Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-21T10:21:35.161Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-21T10:30:25.708Z"
   },
   {
    "duration": 58,
    "start_time": "2022-02-21T10:34:16.279Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-21T10:38:24.005Z"
   },
   {
    "duration": 360,
    "start_time": "2022-02-21T11:10:32.989Z"
   },
   {
    "duration": 83,
    "start_time": "2022-02-21T11:12:17.264Z"
   },
   {
    "duration": 244,
    "start_time": "2022-02-21T11:14:17.214Z"
   },
   {
    "duration": 1035,
    "start_time": "2022-02-21T11:14:37.475Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-21T11:14:38.512Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-21T11:14:38.565Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-21T11:14:38.572Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-21T11:14:38.592Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-21T11:14:38.615Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-21T11:14:38.631Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-21T11:14:38.667Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-21T11:14:38.673Z"
   },
   {
    "duration": 295,
    "start_time": "2022-02-21T11:14:38.685Z"
   },
   {
    "duration": 575,
    "start_time": "2022-02-21T11:14:38.407Z"
   },
   {
    "duration": 559,
    "start_time": "2022-02-21T11:14:38.424Z"
   },
   {
    "duration": 556,
    "start_time": "2022-02-21T11:14:38.428Z"
   },
   {
    "duration": 553,
    "start_time": "2022-02-21T11:14:38.432Z"
   },
   {
    "duration": 549,
    "start_time": "2022-02-21T11:14:38.436Z"
   },
   {
    "duration": 546,
    "start_time": "2022-02-21T11:14:38.440Z"
   },
   {
    "duration": 544,
    "start_time": "2022-02-21T11:14:38.443Z"
   },
   {
    "duration": 542,
    "start_time": "2022-02-21T11:14:38.446Z"
   },
   {
    "duration": 541,
    "start_time": "2022-02-21T11:14:38.448Z"
   },
   {
    "duration": 539,
    "start_time": "2022-02-21T11:14:38.451Z"
   },
   {
    "duration": 1073,
    "start_time": "2022-02-21T11:15:26.639Z"
   },
   {
    "duration": 46,
    "start_time": "2022-02-21T11:15:27.715Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-21T11:15:27.764Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-21T11:15:27.771Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-21T11:15:27.787Z"
   },
   {
    "duration": 50,
    "start_time": "2022-02-21T11:15:27.811Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-21T11:15:27.863Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-21T11:15:27.876Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-21T11:15:27.886Z"
   },
   {
    "duration": 61,
    "start_time": "2022-02-21T11:15:27.900Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-21T11:15:27.963Z"
   },
   {
    "duration": 90,
    "start_time": "2022-02-21T11:15:27.998Z"
   },
   {
    "duration": 74,
    "start_time": "2022-02-21T11:15:28.090Z"
   },
   {
    "duration": 108,
    "start_time": "2022-02-21T11:15:28.167Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-21T11:15:28.277Z"
   },
   {
    "duration": 259,
    "start_time": "2022-02-21T11:15:28.299Z"
   },
   {
    "duration": 106,
    "start_time": "2022-02-21T11:15:28.561Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-21T11:15:28.669Z"
   },
   {
    "duration": 78,
    "start_time": "2022-02-21T11:15:28.690Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-21T11:15:28.770Z"
   },
   {
    "duration": 267,
    "start_time": "2022-02-21T11:15:35.186Z"
   },
   {
    "duration": 1099,
    "start_time": "2022-02-22T13:19:20.298Z"
   },
   {
    "duration": 187,
    "start_time": "2022-02-22T13:19:21.399Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-22T13:19:21.588Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-22T13:19:21.594Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-22T13:19:21.607Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-22T13:19:21.629Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-22T13:19:21.645Z"
   },
   {
    "duration": 4,
    "start_time": "2022-02-22T13:19:21.655Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-22T13:19:21.661Z"
   },
   {
    "duration": 59,
    "start_time": "2022-02-22T13:19:21.673Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-22T13:19:21.733Z"
   },
   {
    "duration": 87,
    "start_time": "2022-02-22T13:19:21.765Z"
   },
   {
    "duration": 80,
    "start_time": "2022-02-22T13:19:21.854Z"
   },
   {
    "duration": 109,
    "start_time": "2022-02-22T13:19:21.937Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-22T13:19:22.048Z"
   },
   {
    "duration": 180,
    "start_time": "2022-02-22T13:19:22.069Z"
   },
   {
    "duration": 107,
    "start_time": "2022-02-22T13:19:22.333Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-22T13:19:22.442Z"
   },
   {
    "duration": 71,
    "start_time": "2022-02-22T13:19:22.461Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-22T13:19:22.534Z"
   },
   {
    "duration": 255,
    "start_time": "2022-02-22T13:19:29.264Z"
   },
   {
    "duration": 426,
    "start_time": "2022-02-22T13:56:55.690Z"
   },
   {
    "duration": 538,
    "start_time": "2022-02-22T13:57:45.736Z"
   },
   {
    "duration": 8506,
    "start_time": "2022-02-22T13:58:26.579Z"
   },
   {
    "duration": 338,
    "start_time": "2022-02-23T08:30:36.078Z"
   },
   {
    "duration": 1311,
    "start_time": "2022-02-23T08:30:40.482Z"
   },
   {
    "duration": 68,
    "start_time": "2022-02-23T08:30:41.795Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T08:30:41.866Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-23T08:30:41.875Z"
   },
   {
    "duration": 68,
    "start_time": "2022-02-23T08:30:41.899Z"
   },
   {
    "duration": 24,
    "start_time": "2022-02-23T08:30:41.969Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-23T08:30:41.996Z"
   },
   {
    "duration": 40,
    "start_time": "2022-02-23T08:30:42.010Z"
   },
   {
    "duration": 17,
    "start_time": "2022-02-23T08:30:42.053Z"
   },
   {
    "duration": 48,
    "start_time": "2022-02-23T08:30:42.072Z"
   },
   {
    "duration": 70,
    "start_time": "2022-02-23T08:30:42.122Z"
   },
   {
    "duration": 131,
    "start_time": "2022-02-23T08:30:42.194Z"
   },
   {
    "duration": 39,
    "start_time": "2022-02-23T08:30:42.328Z"
   },
   {
    "duration": 190,
    "start_time": "2022-02-23T08:30:42.371Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-23T08:30:49.694Z"
   },
   {
    "duration": 350,
    "start_time": "2022-02-23T08:32:28.511Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-23T08:32:43.252Z"
   },
   {
    "duration": 13,
    "start_time": "2022-02-23T08:33:30.593Z"
   },
   {
    "duration": 275,
    "start_time": "2022-02-23T08:42:42.253Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T08:43:12.936Z"
   },
   {
    "duration": 62,
    "start_time": "2022-02-23T08:43:12.943Z"
   },
   {
    "duration": 6,
    "start_time": "2022-02-23T08:43:13.009Z"
   },
   {
    "duration": 52,
    "start_time": "2022-02-23T08:43:13.018Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-23T08:43:13.073Z"
   },
   {
    "duration": 53,
    "start_time": "2022-02-23T08:43:13.110Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-23T08:43:13.165Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T08:43:13.181Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-23T08:43:13.189Z"
   },
   {
    "duration": 81,
    "start_time": "2022-02-23T08:43:13.211Z"
   },
   {
    "duration": 66,
    "start_time": "2022-02-23T08:43:13.295Z"
   },
   {
    "duration": 115,
    "start_time": "2022-02-23T08:43:13.364Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T08:43:13.482Z"
   },
   {
    "duration": 120,
    "start_time": "2022-02-23T08:43:13.550Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-23T08:43:13.673Z"
   },
   {
    "duration": 345,
    "start_time": "2022-02-23T08:43:13.704Z"
   },
   {
    "duration": 115,
    "start_time": "2022-02-23T08:43:14.053Z"
   },
   {
    "duration": 35,
    "start_time": "2022-02-23T08:43:14.171Z"
   },
   {
    "duration": 110,
    "start_time": "2022-02-23T08:43:14.209Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-23T08:43:14.322Z"
   },
   {
    "duration": 413,
    "start_time": "2022-02-23T08:43:14.358Z"
   },
   {
    "duration": 14101,
    "start_time": "2022-02-23T08:43:17.348Z"
   },
   {
    "duration": 89,
    "start_time": "2022-02-23T08:48:41.417Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-23T08:48:56.423Z"
   },
   {
    "duration": 374,
    "start_time": "2022-02-23T09:09:37.757Z"
   },
   {
    "duration": 108,
    "start_time": "2022-02-23T09:10:07.548Z"
   },
   {
    "duration": 24421,
    "start_time": "2022-02-23T09:12:53.794Z"
   },
   {
    "duration": 23748,
    "start_time": "2022-02-23T09:13:31.137Z"
   },
   {
    "duration": 1669,
    "start_time": "2022-02-23T09:14:28.286Z"
   },
   {
    "duration": 91,
    "start_time": "2022-02-23T09:14:29.958Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-23T09:14:30.053Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-23T09:14:30.064Z"
   },
   {
    "duration": 66,
    "start_time": "2022-02-23T09:14:30.096Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T09:14:30.165Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-23T09:14:30.192Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-23T09:14:30.208Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-23T09:14:30.253Z"
   },
   {
    "duration": 47,
    "start_time": "2022-02-23T09:14:30.278Z"
   },
   {
    "duration": 63,
    "start_time": "2022-02-23T09:14:30.327Z"
   },
   {
    "duration": 124,
    "start_time": "2022-02-23T09:14:30.393Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-23T09:14:30.519Z"
   },
   {
    "duration": 123,
    "start_time": "2022-02-23T09:14:30.650Z"
   },
   {
    "duration": 29,
    "start_time": "2022-02-23T09:14:30.775Z"
   },
   {
    "duration": 344,
    "start_time": "2022-02-23T09:14:30.806Z"
   },
   {
    "duration": 109,
    "start_time": "2022-02-23T09:14:31.153Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-23T09:14:31.264Z"
   },
   {
    "duration": 113,
    "start_time": "2022-02-23T09:14:31.292Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-23T09:14:31.407Z"
   },
   {
    "duration": 120,
    "start_time": "2022-02-23T09:14:31.448Z"
   },
   {
    "duration": 25000,
    "start_time": "2022-02-23T09:14:42.783Z"
   },
   {
    "duration": 24582,
    "start_time": "2022-02-23T09:15:09.650Z"
   },
   {
    "duration": 9171,
    "start_time": "2022-02-23T09:19:14.193Z"
   },
   {
    "duration": 446,
    "start_time": "2022-02-23T09:25:54.211Z"
   },
   {
    "duration": 101,
    "start_time": "2022-02-23T09:26:11.979Z"
   },
   {
    "duration": 9900,
    "start_time": "2022-02-23T09:26:15.386Z"
   },
   {
    "duration": 9464,
    "start_time": "2022-02-23T09:26:55.889Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-23T09:27:11.835Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T09:37:01.949Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T09:38:26.238Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T09:40:55.599Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-23T09:41:28.381Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-23T09:45:38.951Z"
   },
   {
    "duration": 491,
    "start_time": "2022-02-23T09:52:21.790Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T09:52:48.505Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-23T09:56:07.405Z"
   },
   {
    "duration": 1309,
    "start_time": "2022-02-23T10:02:19.862Z"
   },
   {
    "duration": 65,
    "start_time": "2022-02-23T10:02:21.174Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T10:02:21.249Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-23T10:02:21.259Z"
   },
   {
    "duration": 67,
    "start_time": "2022-02-23T10:02:21.283Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T10:02:21.352Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-23T10:02:21.380Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T10:02:21.395Z"
   },
   {
    "duration": 55,
    "start_time": "2022-02-23T10:02:21.403Z"
   },
   {
    "duration": 47,
    "start_time": "2022-02-23T10:02:21.461Z"
   },
   {
    "duration": 63,
    "start_time": "2022-02-23T10:02:21.511Z"
   },
   {
    "duration": 122,
    "start_time": "2022-02-23T10:02:21.576Z"
   },
   {
    "duration": 56,
    "start_time": "2022-02-23T10:02:21.701Z"
   },
   {
    "duration": 130,
    "start_time": "2022-02-23T10:02:21.850Z"
   },
   {
    "duration": 36,
    "start_time": "2022-02-23T10:02:21.983Z"
   },
   {
    "duration": 330,
    "start_time": "2022-02-23T10:02:22.021Z"
   },
   {
    "duration": 111,
    "start_time": "2022-02-23T10:02:22.354Z"
   },
   {
    "duration": 81,
    "start_time": "2022-02-23T10:02:22.468Z"
   },
   {
    "duration": 98,
    "start_time": "2022-02-23T10:02:22.551Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-23T10:02:22.651Z"
   },
   {
    "duration": 127,
    "start_time": "2022-02-23T10:02:22.671Z"
   },
   {
    "duration": 9767,
    "start_time": "2022-02-23T10:02:22.801Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-23T10:02:32.573Z"
   },
   {
    "duration": 52,
    "start_time": "2022-02-23T10:02:32.606Z"
   },
   {
    "duration": 9,
    "start_time": "2022-02-23T10:02:32.661Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-23T10:02:32.673Z"
   },
   {
    "duration": 1457,
    "start_time": "2022-02-23T10:04:08.618Z"
   },
   {
    "duration": 73,
    "start_time": "2022-02-23T10:04:10.077Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T10:04:10.153Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-23T10:04:10.163Z"
   },
   {
    "duration": 73,
    "start_time": "2022-02-23T10:04:10.188Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-23T10:04:10.264Z"
   },
   {
    "duration": 11,
    "start_time": "2022-02-23T10:04:10.288Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T10:04:10.303Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-23T10:04:10.313Z"
   },
   {
    "duration": 46,
    "start_time": "2022-02-23T10:04:10.367Z"
   },
   {
    "duration": 74,
    "start_time": "2022-02-23T10:04:10.416Z"
   },
   {
    "duration": 124,
    "start_time": "2022-02-23T10:04:10.493Z"
   },
   {
    "duration": 46,
    "start_time": "2022-02-23T10:04:10.619Z"
   },
   {
    "duration": 124,
    "start_time": "2022-02-23T10:04:10.750Z"
   },
   {
    "duration": 26,
    "start_time": "2022-02-23T10:04:10.876Z"
   },
   {
    "duration": 345,
    "start_time": "2022-02-23T10:04:10.904Z"
   },
   {
    "duration": 111,
    "start_time": "2022-02-23T10:04:11.253Z"
   },
   {
    "duration": 38,
    "start_time": "2022-02-23T10:04:11.366Z"
   },
   {
    "duration": 101,
    "start_time": "2022-02-23T10:04:11.406Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-23T10:04:11.510Z"
   },
   {
    "duration": 125,
    "start_time": "2022-02-23T10:04:11.531Z"
   },
   {
    "duration": 9500,
    "start_time": "2022-02-23T10:04:11.659Z"
   },
   {
    "duration": 32,
    "start_time": "2022-02-23T10:04:21.165Z"
   },
   {
    "duration": 54,
    "start_time": "2022-02-23T10:04:21.200Z"
   },
   {
    "duration": 10,
    "start_time": "2022-02-23T10:04:21.257Z"
   },
   {
    "duration": 15,
    "start_time": "2022-02-23T10:04:21.270Z"
   },
   {
    "duration": 20,
    "start_time": "2022-02-23T12:28:55.590Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-23T12:29:16.661Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T12:47:02.641Z"
   },
   {
    "duration": 147,
    "start_time": "2022-02-23T12:47:02.650Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T12:47:02.800Z"
   },
   {
    "duration": 41,
    "start_time": "2022-02-23T12:47:02.810Z"
   },
   {
    "duration": 42,
    "start_time": "2022-02-23T12:47:02.854Z"
   },
   {
    "duration": 57,
    "start_time": "2022-02-23T12:47:02.898Z"
   },
   {
    "duration": 14,
    "start_time": "2022-02-23T12:47:02.960Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T12:47:02.977Z"
   },
   {
    "duration": 28,
    "start_time": "2022-02-23T12:47:02.986Z"
   },
   {
    "duration": 93,
    "start_time": "2022-02-23T12:47:03.016Z"
   },
   {
    "duration": 80,
    "start_time": "2022-02-23T12:47:03.112Z"
   },
   {
    "duration": 167,
    "start_time": "2022-02-23T12:47:03.195Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-23T12:47:03.365Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-23T12:47:17.038Z"
   },
   {
    "duration": 104,
    "start_time": "2022-02-23T13:10:33.453Z"
   },
   {
    "duration": 11499,
    "start_time": "2022-02-23T13:10:41.839Z"
   },
   {
    "duration": 107,
    "start_time": "2022-02-23T13:11:12.453Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T13:19:35.968Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T13:31:31.687Z"
   },
   {
    "duration": 193,
    "start_time": "2022-02-23T13:31:34.570Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-23T13:31:38.414Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-23T13:31:51.224Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-23T13:45:54.325Z"
   },
   {
    "duration": 1401,
    "start_time": "2022-02-23T13:46:12.317Z"
   },
   {
    "duration": 72,
    "start_time": "2022-02-23T13:46:13.721Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-23T13:46:13.796Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-23T13:46:13.806Z"
   },
   {
    "duration": 44,
    "start_time": "2022-02-23T13:46:13.831Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T13:46:13.878Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-23T13:46:13.907Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T13:46:13.923Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-23T13:46:13.931Z"
   },
   {
    "duration": 51,
    "start_time": "2022-02-23T13:46:13.963Z"
   },
   {
    "duration": 37,
    "start_time": "2022-02-23T13:46:14.017Z"
   },
   {
    "duration": 200,
    "start_time": "2022-02-23T13:46:14.057Z"
   },
   {
    "duration": 92,
    "start_time": "2022-02-23T13:46:14.259Z"
   },
   {
    "duration": 120,
    "start_time": "2022-02-23T13:46:14.355Z"
   },
   {
    "duration": 512,
    "start_time": "2022-02-23T13:46:14.478Z"
   },
   {
    "duration": 822,
    "start_time": "2022-02-23T13:46:14.170Z"
   },
   {
    "duration": 547,
    "start_time": "2022-02-23T13:47:32.095Z"
   },
   {
    "duration": 76,
    "start_time": "2022-02-23T13:47:57.224Z"
   },
   {
    "duration": 7359,
    "start_time": "2022-02-23T13:48:11.860Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-23T13:48:30.358Z"
   },
   {
    "duration": 542,
    "start_time": "2022-02-23T13:50:28.086Z"
   },
   {
    "duration": 343,
    "start_time": "2022-02-23T13:50:52.604Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-23T13:51:54.941Z"
   },
   {
    "duration": 1560,
    "start_time": "2022-02-23T13:53:05.027Z"
   },
   {
    "duration": 79,
    "start_time": "2022-02-23T13:53:06.590Z"
   },
   {
    "duration": 8,
    "start_time": "2022-02-23T13:53:06.672Z"
   },
   {
    "duration": 24,
    "start_time": "2022-02-23T13:53:06.683Z"
   },
   {
    "duration": 64,
    "start_time": "2022-02-23T13:53:06.710Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T13:53:06.777Z"
   },
   {
    "duration": 49,
    "start_time": "2022-02-23T13:53:06.804Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T13:53:06.857Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T13:53:06.866Z"
   },
   {
    "duration": 87,
    "start_time": "2022-02-23T13:53:06.895Z"
   },
   {
    "duration": 27,
    "start_time": "2022-02-23T13:53:06.985Z"
   },
   {
    "duration": 213,
    "start_time": "2022-02-23T13:53:07.015Z"
   },
   {
    "duration": 217,
    "start_time": "2022-02-23T13:53:07.231Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-23T13:53:07.451Z"
   },
   {
    "duration": 97,
    "start_time": "2022-02-23T13:53:07.484Z"
   },
   {
    "duration": 7057,
    "start_time": "2022-02-23T13:53:07.584Z"
   },
   {
    "duration": 23,
    "start_time": "2022-02-23T13:53:14.643Z"
   },
   {
    "duration": 381,
    "start_time": "2022-02-23T13:53:14.669Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-23T13:53:20.120Z"
   },
   {
    "duration": 372,
    "start_time": "2022-02-23T13:56:41.577Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-23T13:56:47.400Z"
   },
   {
    "duration": 458,
    "start_time": "2022-02-23T14:02:11.045Z"
   },
   {
    "duration": 86,
    "start_time": "2022-02-23T14:02:45.300Z"
   },
   {
    "duration": 280,
    "start_time": "2022-02-23T14:03:03.501Z"
   },
   {
    "duration": 390,
    "start_time": "2022-02-23T14:03:16.469Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-23T14:03:23.107Z"
   },
   {
    "duration": 105,
    "start_time": "2022-02-23T14:03:25.649Z"
   },
   {
    "duration": 22,
    "start_time": "2022-02-23T14:03:28.715Z"
   },
   {
    "duration": 15546,
    "start_time": "2022-02-23T14:21:38.809Z"
   },
   {
    "duration": 15895,
    "start_time": "2022-02-23T14:22:11.836Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-23T14:26:03.880Z"
   },
   {
    "duration": 47,
    "start_time": "2022-02-23T14:26:07.209Z"
   },
   {
    "duration": 7854,
    "start_time": "2022-02-23T14:26:40.518Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-23T14:27:42.605Z"
   },
   {
    "duration": 339,
    "start_time": "2022-02-23T14:29:22.402Z"
   },
   {
    "duration": 21,
    "start_time": "2022-02-23T14:29:28.060Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-23T14:33:55.204Z"
   },
   {
    "duration": 12,
    "start_time": "2022-02-23T14:34:22.950Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-23T14:35:34.686Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T14:37:31.834Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-23T17:31:43.151Z"
   },
   {
    "duration": 323,
    "start_time": "2022-02-23T17:39:31.638Z"
   },
   {
    "duration": 122,
    "start_time": "2022-02-23T17:41:15.930Z"
   },
   {
    "duration": 399,
    "start_time": "2022-02-23T17:41:27.223Z"
   },
   {
    "duration": 329,
    "start_time": "2022-02-23T17:43:04.563Z"
   },
   {
    "duration": 340,
    "start_time": "2022-02-23T17:46:45.274Z"
   },
   {
    "duration": 325,
    "start_time": "2022-02-23T17:47:40.860Z"
   },
   {
    "duration": 494,
    "start_time": "2022-02-23T17:48:01.573Z"
   },
   {
    "duration": 232,
    "start_time": "2022-02-24T08:07:41.451Z"
   },
   {
    "duration": 1147,
    "start_time": "2022-02-24T08:07:46.721Z"
   },
   {
    "duration": 53,
    "start_time": "2022-02-24T08:07:47.871Z"
   },
   {
    "duration": 5,
    "start_time": "2022-02-24T08:07:47.926Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-24T08:07:47.933Z"
   },
   {
    "duration": 31,
    "start_time": "2022-02-24T08:07:47.960Z"
   },
   {
    "duration": 16,
    "start_time": "2022-02-24T08:07:47.993Z"
   },
   {
    "duration": 7,
    "start_time": "2022-02-24T08:07:48.010Z"
   },
   {
    "duration": 19,
    "start_time": "2022-02-24T08:07:48.019Z"
   },
   {
    "duration": 33,
    "start_time": "2022-02-24T08:07:48.040Z"
   },
   {
    "duration": 39,
    "start_time": "2022-02-24T08:07:48.075Z"
   },
   {
    "duration": 45,
    "start_time": "2022-02-24T08:07:48.116Z"
   },
   {
    "duration": 137,
    "start_time": "2022-02-24T08:07:48.163Z"
   },
   {
    "duration": 69,
    "start_time": "2022-02-24T08:07:48.301Z"
   },
   {
    "duration": 190,
    "start_time": "2022-02-24T08:07:48.373Z"
   },
   {
    "duration": 56,
    "start_time": "2022-02-24T08:07:48.565Z"
   },
   {
    "duration": 7631,
    "start_time": "2022-02-24T08:07:48.623Z"
   },
   {
    "duration": 18,
    "start_time": "2022-02-24T08:07:56.260Z"
   },
   {
    "duration": 91,
    "start_time": "2022-02-24T08:07:56.280Z"
   },
   {
    "duration": 10974,
    "start_time": "2022-02-24T08:07:56.373Z"
   },
   {
    "duration": 233,
    "start_time": "2022-02-24T08:08:07.348Z"
   },
   {
    "duration": 87,
    "start_time": "2022-02-24T08:08:07.584Z"
   },
   {
    "duration": 108,
    "start_time": "2022-02-24T08:08:07.674Z"
   },
   {
    "duration": 34,
    "start_time": "2022-02-24T08:08:07.785Z"
   },
   {
    "duration": 5169,
    "start_time": "2022-02-24T08:08:07.821Z"
   },
   {
    "duration": 267,
    "start_time": "2022-02-24T08:08:12.992Z"
   },
   {
    "duration": 104,
    "start_time": "2022-02-24T08:08:13.263Z"
   },
   {
    "duration": 30,
    "start_time": "2022-02-24T08:08:20.058Z"
   },
   {
    "duration": 383,
    "start_time": "2022-02-24T08:09:58.382Z"
   },
   {
    "duration": 70,
    "start_time": "2022-02-24T08:10:03.794Z"
   },
   {
    "duration": 25,
    "start_time": "2022-02-24T08:10:12.642Z"
   },
   {
    "duration": 216,
    "start_time": "2022-02-24T08:11:02.454Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
